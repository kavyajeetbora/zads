{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuQOWqFqmYBx9T3m9PKgJf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajeetbora/zads/blob/master/development/03_real_estate_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json"
      ],
      "metadata": {
        "id": "3oGeDBJ2C0U7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the coordinates data can also be listed using regex pattern:\n",
        "\n",
        "```\n",
        "\\d+\\.\\d+, \\d+\\.\\d+\n",
        "```\n",
        "\n",
        "after this filter out the invalid coodinates"
      ],
      "metadata": {
        "id": "ym55oTlDOmCk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "yvV51oaGClun"
      },
      "outputs": [],
      "source": [
        "HEADER = {\n",
        "      'User-Agent': 'Mozilla/5.0 (X11; CrOS x86_64 14541.0.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
        "      'Cookie': \"place_your_cookie_here\",\n",
        "      'Referer': 'https://www.google.com/',\n",
        "      'Accept' : '*/*',\n",
        "      'Accept-Language' : 'en-US,en;q=0.9'\n",
        "}\n",
        "\n",
        "URL = \"https://www.google.com/search\"\n",
        "\n",
        "\n",
        "def geocoder(place_name):\n",
        "\n",
        "    PARAMS = {\n",
        "        'tbm': 'map',\n",
        "        'authuser': '0',\n",
        "        'hl': 'en',\n",
        "        'q': place_name,\n",
        "        'tch': '1',\n",
        "        'ech': '5'\n",
        "    }\n",
        "\n",
        "    response = requests.get(URL, params=PARAMS, headers=HEADER)\n",
        "    messy_data = response.text\n",
        "\n",
        "    data = json.loads(messy_data[:-6])\n",
        "    javascript_array_str = data[\"d\"][5:]\n",
        "    python_list = json.loads(javascript_array_str)\n",
        "    places_data = python_list[0][1]\n",
        "\n",
        "    _, lon, lat = python_list[1][0]\n",
        "    return lat, lon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "place_name = \"Pareena Micasa, Sector 68, Gurugram, Haryana 122101\"\n",
        "geocoder(place_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTMXA-FkD-L5",
        "outputId": "d23d424e-bf79-4574-e33f-668bd90a032c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28.388229299999995, 77.0420637)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping from 99 acres\n"
      ],
      "metadata": {
        "id": "66Gyd5g7nJVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fake_useragent"
      ],
      "metadata": {
        "id": "rQJV3nt9nrbg"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from fake_useragent import UserAgent\n",
        "from lxml import html, etree"
      ],
      "metadata": {
        "id": "vQ8ZSsP3nozJ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_user_agent():\n",
        "    try:\n",
        "        ua = UserAgent()\n",
        "        return ua.random\n",
        "    except:\n",
        "        # Fallback user agents if fake_useragent fails\n",
        "        user_agents = [\n",
        "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
        "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
        "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/120.0.0.0 Safari/537.36',\n",
        "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15'\n",
        "        ]\n",
        "        return random.choice(user_agents)\n",
        "\n",
        "def make_request(url):\n",
        "    # Headers to mimic a browser\n",
        "    headers = {\n",
        "        'User-Agent': get_random_user_agent(),\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
        "        'Accept-Language': 'en-US,en;q=0.9',\n",
        "        'Accept-Encoding': 'gzip, deflate, br',\n",
        "        'Connection': 'keep-alive',\n",
        "        'Upgrade-Insecure-Requests': '1',\n",
        "        'Cache-Control': 'max-age=0',\n",
        "        'DNT': '1',  # Do Not Track\n",
        "        'Sec-Fetch-Dest': 'document',\n",
        "        'Sec-Fetch-Mode': 'navigate',\n",
        "        'Sec-Fetch-Site': 'none',\n",
        "        'Sec-Fetch-User': '?1',\n",
        "    }\n",
        "\n",
        "    # Parameters for the request\n",
        "    params = {\n",
        "        'city': '8',\n",
        "        # Add any additional parameters needed\n",
        "        'preference': 'S',  # S for Sale\n",
        "        'area_unit': '1',   # Square Feet\n",
        "        'res_com': 'R',     # Residential\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Make the request with a timeout\n",
        "        response = requests.get(\n",
        "            url,\n",
        "            headers=headers,\n",
        "            params=params,\n",
        "            timeout=30,\n",
        "            verify=True  # SSL verification\n",
        "        )\n",
        "\n",
        "        # Raise an exception for bad status codes\n",
        "        response.raise_for_status()\n",
        "\n",
        "        return response\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error making request: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "Mab59t72n5es"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "city_url = 'https://www.99acres.com/search/property/buy/'\n",
        "response = make_request(city_url)\n",
        "\n",
        "if response and response.status_code == 200:\n",
        "    print(\"Request successful!\")\n",
        "else:\n",
        "    print(\"Request failed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8l1afc8nLur",
        "outputId": "55fafe8d-3f09-4ce9-e847-b764ddb1b6e1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create etree from response text\n",
        "tree = html.fromstring(response.content)\n",
        "\n",
        "# Make links absolute (optional but recommended)\n",
        "tree.make_links_absolute(response.url)"
      ],
      "metadata": {
        "id": "fwRwx0Mqpe1_"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cards = tree.xpath('''//*[@class=\"ellipsis\"]''')\n",
        "for card in cards:\n",
        "    print(card.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc_AelsYp0BD",
        "outputId": "84d85df2-4a17-4b97-a453-5218fe8d1448"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ganga Anantam\n",
            "M3M Mansion\n",
            "M3M Antalya Hills\n",
            "Smartworld One DXP\n",
            "Puri Diplomatic Residences\n",
            "Godrej Zenith\n",
            "Signature Global Titanium SPR\n",
            "Elan The Presidential\n",
            "M3M Altitude\n",
            "Godrej Aristocrat\n",
            "Silverglades The Legacy\n",
            "Whiteland The Aspen\n",
            "Krisumi Waterside Residences\n",
            "Smartworld The Edition\n",
            "TARC Ishva\n",
            "Pyramid Alban\n",
            "M3M Golf Hills\n",
            "M3M Crown\n",
            "4S The Aurrum\n",
            "Ganga Nandaka\n",
            "Signature Global Daxin Vistas\n",
            "Oxirich Chintamanis\n",
            "M3M Capital\n",
            "Adani Lushlands\n",
            "Sobha Aranya\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lxml import html, etree\n",
        "import requests\n",
        "from urllib.parse import urljoin\n",
        "import re\n",
        "\n",
        "def create_etree(response):\n",
        "    \"\"\"\n",
        "    Creates an lxml etree from response text and handles common errors\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create etree from response text\n",
        "        tree = html.fromstring(response.content)\n",
        "\n",
        "        # Make links absolute (optional but recommended)\n",
        "        tree.make_links_absolute(response.url)\n",
        "\n",
        "        return tree\n",
        "\n",
        "    except etree.ParserError as e:\n",
        "        print(f\"Parser error: {e}\")\n",
        "        # Try cleaning the HTML first\n",
        "        cleaned_html = clean_html(response.text)\n",
        "        return html.fromstring(cleaned_html)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating etree: {e}\")\n",
        "        return None\n",
        "\n",
        "def clean_html(html_text):\n",
        "    \"\"\"\n",
        "    Cleans problematic HTML content\n",
        "    \"\"\"\n",
        "    # Remove null bytes\n",
        "    html_text = html_text.replace('\\x00', '')\n",
        "\n",
        "    # Fix common HTML issues\n",
        "    html_text = re.sub(r'<\\s+', '<', html_text)  # Fix tags with extra spaces\n",
        "    html_text = re.sub(r'\\s+>', '>', html_text)\n",
        "\n",
        "    # Fix unclosed tags (basic)\n",
        "    common_tags = ['div', 'span', 'p', 'a', 'li', 'ul', 'table', 'tr', 'td']\n",
        "    for tag in common_tags:\n",
        "        pattern = f'<{tag}(?![^>]*/>)[^>]*>'\n",
        "        closing_pattern = f'</{tag}>'\n",
        "        opens = len(re.findall(pattern, html_text, re.IGNORECASE))\n",
        "        closes = len(re.findall(closing_pattern, html_text, re.IGNORECASE))\n",
        "        # Add missing closing tags\n",
        "        if opens > closes:\n",
        "            html_text += f'</{tag}>' * (opens - closes)\n",
        "\n",
        "    return html_text\n",
        "\n",
        "def parse_99acres(response):\n",
        "    \"\"\"\n",
        "    Parse 99acres.com property listings\n",
        "    \"\"\"\n",
        "    if not response or response.status_code != 200:\n",
        "        print(\"Invalid response\")\n",
        "        return None\n",
        "\n",
        "    # Create etree\n",
        "    tree = create_etree(response)\n",
        "    if tree is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Example parsing (adjust XPaths based on actual HTML structure)\n",
        "        properties = []\n",
        "\n",
        "        # Find all property listings\n",
        "        listing_xpath = \"//div[contains(@class, 'property-listing')]\"  # Adjust this\n",
        "        listings = tree.xpath(listing_xpath)\n",
        "\n",
        "        for listing in listings:\n",
        "            try:\n",
        "                property_data = {\n",
        "                    'title': get_text(listing, \".//h2\"),\n",
        "                    'price': get_text(listing, \".//div[contains(@class, 'price')]\"),\n",
        "                    'location': get_text(listing, \".//div[contains(@class, 'location')]\"),\n",
        "                    'area': get_text(listing, \".//div[contains(@class, 'area')]\"),\n",
        "                    'link': get_attr(listing, \".//a[@class='property-link']\", 'href'),\n",
        "                }\n",
        "                properties.append(property_data)\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing listing: {e}\")\n",
        "                continue\n",
        "\n",
        "        return properties\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing page: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_text(element, xpath, default=''):\n",
        "    \"\"\"\n",
        "    Safely extract text from an xpath\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = element.xpath(xpath)\n",
        "        if result:\n",
        "            return ' '.join(result[0].text_content().split())\n",
        "        return default\n",
        "    except:\n",
        "        return default\n",
        "\n",
        "def get_attr(element, xpath, attr, default=''):\n",
        "    \"\"\"\n",
        "    Safely extract attribute from an xpath\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = element.xpath(xpath)\n",
        "        if result:\n",
        "            return result[0].get(attr, default)\n",
        "        return default\n",
        "    except:\n",
        "        return default\n",
        "\n",
        "\n",
        "city_url = 'https://www.99acres.com/search/property/buy/'\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
        "}\n",
        "params = {'city': '8'}\n",
        "\n",
        "try:\n",
        "    response = requests.get(city_url, headers=headers, params=params, timeout=30)\n",
        "    properties = parse_99acres(response)\n",
        "\n",
        "    if properties:\n",
        "        print(f\"Found {len(properties)} properties\")\n",
        "        for prop in properties:\n",
        "            print(\"\\nProperty Details:\")\n",
        "            for key, value in prop.items():\n",
        "                print(f\"{key}: {value}\")\n",
        "    else:\n",
        "        print(\"No properties found or error occurred\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error in main: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8pVMOXOpIdY",
        "outputId": "f213c10c-1b0b-49f5-b3cd-4e53dbef87e9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in main: HTTPSConnectionPool(host='www.99acres.com', port=443): Read timed out. (read timeout=30)\n"
          ]
        }
      ]
    }
  ]
}